# ğŸ® Subway Surfers Control Using Pose Detection

This project demonstrates a **real-time Humanâ€“Computer Interaction (HCI)** system where the game **Subway Surfers** is controlled using **body gestures** captured through a webcam.

Using **MediaPipe Pose**, **OpenCV**, and **PyAutoGUI**, the system detects human pose landmarks, interprets body movements, and converts them into **keyboard inputs** to control the game character.

---

## ğŸ“Œ Features
* **Touchless Gameplay:** Play without touching the keyboard.
* **Gesture Recognition:**
    * **Start Game:** Join hands (Namaste pose) to start and calibrate.
    * **Lane Changing:** Lean Left or Right.
    * **Jumping & Crouching:** Stand tall to jump, duck down to crouch.
* **Real-time Processing:** Smooth performance using MediaPipe's lightweight pose detection.
* **Visual Feedback:** On-screen pose landmarks and FPS counter.

---

## ğŸ› ï¸ Technologies Used
* **Python 3.x**
* **OpenCV:** For video capture and image processing.
* **MediaPipe:** For robust human pose estimation.
* **PyAutoGUI:** For simulating keyboard presses.

---

## ğŸ“ Project Structure
Subway Surfers/
â”‚
â”œâ”€â”€ pose_utils.py # Pose detection logic
â”œâ”€â”€ gesture_utils.py # Gesture detection functions
â”œâ”€â”€ main.py # Final application (game controller)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ğŸš€ Getting Started

### 1. Clone the Repository
Open your terminal or command prompt and run:
```bash
git clone (https://github.com/Parth-bot-crypto26/Subway-Surfers-Pose-Control.git)
cd subway-surfers-pose-control
